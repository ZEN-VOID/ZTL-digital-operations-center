#!/usr/bin/env python3
"""
ResultAggregator - ç»“æœæ±‡æ€»å™¨
ç›‘æ§å¹¶æ±‡æ€»æ‰€æœ‰Workerçš„æ‰§è¡Œç»“æœ,ç”Ÿæˆå®Œæ•´æŠ¥å‘Š

Version: 1.0.0
Created: 2025-11-01
"""

import json
import time
from pathlib import Path
from typing import List, Dict, Optional, Any
from datetime import datetime
from dataclasses import dataclass


@dataclass
class TaskResult:
    """ä»»åŠ¡ç»“æœæ•°æ®ç»“æ„"""
    task_id: str
    status: str
    execution_time: str
    duration_seconds: Optional[int]
    output_data: Dict[str, Any]
    summary: str
    errors: List[str]
    warnings: List[str]
    next_steps: List[str]


class ResultAggregator:
    """ç»“æœæ±‡æ€»å™¨"""

    def __init__(self, project_name: str = "default-project"):
        """
        åˆå§‹åŒ–ç»“æœæ±‡æ€»å™¨

        Args:
            project_name: é¡¹ç›®åç§°
        """
        self.project_name = project_name
        self.task_queue_dir = Path(f"output/{project_name}/task-queue")
        self.results_dir = Path(f"output/{project_name}/results")
        self.report_path = Path(f"output/{project_name}/final-report.md")

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.results_dir.mkdir(parents=True, exist_ok=True)

    def monitor_and_aggregate(
        self,
        check_interval: int = 10,
        max_wait_time: int = 3600
    ) -> str:
        """
        æŒç»­ç›‘æ§ä»»åŠ¡é˜Ÿåˆ—,æ”¶é›†å®Œæˆçš„ç»“æœå¹¶ç”ŸæˆæŠ¥å‘Š

        Args:
            check_interval: æ£€æŸ¥é—´éš”(ç§’)
            max_wait_time: æœ€å¤§ç­‰å¾…æ—¶é—´(ç§’)

        Returns:
            æœ€ç»ˆæŠ¥å‘Šè·¯å¾„
        """
        print(f"ğŸ” å¼€å§‹ç›‘æ§ä»»åŠ¡æ‰§è¡Œ...")
        print(f"   ä»»åŠ¡é˜Ÿåˆ—: {self.task_queue_dir}")
        print(f"   ç»“æœç›®å½•: {self.results_dir}")
        print(f"   æ£€æŸ¥é—´éš”: {check_interval}ç§’")

        start_time = time.time()
        all_tasks = self._load_all_tasks()
        completed_results = {}

        if not all_tasks:
            print("âš ï¸  è­¦å‘Š: ä»»åŠ¡é˜Ÿåˆ—ä¸ºç©º")
            return str(self.report_path)

        print(f"ğŸ“‹ æ€»ä»»åŠ¡æ•°: {len(all_tasks)}")
        self._print_task_status(all_tasks)

        # æŒç»­ç›‘æ§ç›´åˆ°æ‰€æœ‰ä»»åŠ¡å®Œæˆæˆ–è¶…æ—¶
        while not self._all_tasks_completed(all_tasks):
            elapsed_time = time.time() - start_time

            if elapsed_time > max_wait_time:
                print(f"â° è¶…æ—¶: å·²ç­‰å¾… {elapsed_time:.0f} ç§’,åœæ­¢ç›‘æ§")
                break

            time.sleep(check_interval)

            # é‡æ–°åŠ è½½ä»»åŠ¡çŠ¶æ€
            all_tasks = self._load_all_tasks()

            # æ”¶é›†æ–°å®Œæˆçš„ç»“æœ
            for task in all_tasks:
                if task['status'] == 'completed' and task['task_id'] not in completed_results:
                    result = self._load_result(task['output_path'])
                    if result:
                        completed_results[task['task_id']] = result
                        print(f"âœ… æ”¶é›†åˆ°ä»»åŠ¡ç»“æœ: {task['task_id']} - {task['description']}")

            # æ‰“å°è¿›åº¦
            completed_count = len([t for t in all_tasks if t['status'] == 'completed'])
            failed_count = len([t for t in all_tasks if t['status'] == 'failed'])
            print(f"ğŸ“Š è¿›åº¦: {completed_count}/{len(all_tasks)} å®Œæˆ, {failed_count} å¤±è´¥")

        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        print("\nğŸ“ ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
        final_report = self._generate_report(all_tasks, completed_results)

        # ä¿å­˜æŠ¥å‘Š
        with open(self.report_path, 'w', encoding='utf-8') as f:
            f.write(final_report)

        print(f"âœ… æœ€ç»ˆæŠ¥å‘Šå·²ä¿å­˜: {self.report_path}")
        return str(self.report_path)

    def _load_all_tasks(self) -> List[Dict]:
        """åŠ è½½æ‰€æœ‰ä»»åŠ¡é…ç½®"""
        tasks = []

        if not self.task_queue_dir.exists():
            return tasks

        for task_file in sorted(self.task_queue_dir.glob("task-*.json")):
            try:
                with open(task_file, 'r', encoding='utf-8') as f:
                    task_data = json.load(f)
                    tasks.append(task_data)
            except Exception as e:
                print(f"âŒ è¯»å–ä»»åŠ¡æ–‡ä»¶å¤±è´¥: {task_file} - {e}")

        return tasks

    def _load_result(self, output_path: str) -> Optional[Dict]:
        """åŠ è½½å•ä¸ªä»»åŠ¡ç»“æœ"""
        result_file = Path(output_path)

        if not result_file.exists():
            return None

        try:
            with open(result_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥: {result_file} - {e}")
            return None

    def _all_tasks_completed(self, tasks: List[Dict]) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ä»»åŠ¡éƒ½å·²å®Œæˆ"""
        if not tasks:
            return True

        return all(
            task['status'] in ['completed', 'failed']
            for task in tasks
        )

    def _print_task_status(self, tasks: List[Dict]):
        """æ‰“å°ä»»åŠ¡çŠ¶æ€æ‘˜è¦"""
        status_counts = {
            'pending': 0,
            'running': 0,
            'completed': 0,
            'failed': 0
        }

        for task in tasks:
            status = task.get('status', 'pending')
            status_counts[status] = status_counts.get(status, 0) + 1

        print("\nä»»åŠ¡çŠ¶æ€:")
        print(f"  â³ å¾…æ‰§è¡Œ: {status_counts['pending']}")
        print(f"  ğŸ”„ æ‰§è¡Œä¸­: {status_counts['running']}")
        print(f"  âœ… å·²å®Œæˆ: {status_counts['completed']}")
        print(f"  âŒ å·²å¤±è´¥: {status_counts['failed']}")
        print()

    def _generate_report(
        self,
        tasks: List[Dict],
        results: Dict[str, Dict]
    ) -> str:
        """
        ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š

        Args:
            tasks: æ‰€æœ‰ä»»åŠ¡åˆ—è¡¨
            results: å·²æ”¶é›†çš„ç»“æœå­—å…¸

        Returns:
            Markdownæ ¼å¼æŠ¥å‘Š
        """
        report_lines = []

        # æŠ¥å‘Šæ ‡é¢˜
        report_lines.append(f"# ä»»åŠ¡æ‰§è¡Œæ€»æŠ¥å‘Š")
        report_lines.append(f"\n**é¡¹ç›®åç§°**: {self.project_name}")
        report_lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append(f"**æ€»ä»»åŠ¡æ•°**: {len(tasks)}")

        # æ‰§è¡Œæ‘˜è¦
        completed_tasks = [t for t in tasks if t['status'] == 'completed']
        failed_tasks = [t for t in tasks if t['status'] == 'failed']
        pending_tasks = [t for t in tasks if t['status'] in ['pending', 'running']]

        report_lines.append("\n## ğŸ“Š æ‰§è¡Œæ‘˜è¦\n")
        report_lines.append(f"- âœ… å·²å®Œæˆ: {len(completed_tasks)}/{len(tasks)}")
        report_lines.append(f"- âŒ å·²å¤±è´¥: {len(failed_tasks)}/{len(tasks)}")
        report_lines.append(f"- â³ æœªå®Œæˆ: {len(pending_tasks)}/{len(tasks)}")

        # è®¡ç®—æ€»æ‰§è¡Œæ—¶é—´
        if completed_tasks:
            total_duration = sum(
                results.get(t['task_id'], {}).get('duration_seconds', 0)
                for t in completed_tasks
            )
            report_lines.append(f"- â±ï¸  æ€»æ‰§è¡Œæ—¶é—´: {total_duration} ç§’ ({total_duration/60:.1f} åˆ†é’Ÿ)")

        # æŒ‰ä¾èµ–å…³ç³»æ’åºä»»åŠ¡
        sorted_tasks = self._topological_sort(tasks)

        # è¯¦ç»†ç»“æœ
        report_lines.append("\n## ğŸ“‹ è¯¦ç»†ç»“æœ\n")

        for i, task in enumerate(sorted_tasks, 1):
            task_id = task['task_id']
            result = results.get(task_id, {})

            report_lines.append(f"### é˜¶æ®µ{i}: {task['description']} ({task_id})")
            report_lines.append(f"\n**çŠ¶æ€**: {self._format_status(task['status'])}")

            if task['dependencies']:
                report_lines.append(f"**ä¾èµ–ä»»åŠ¡**: {', '.join(task['dependencies'])}")

            if task.get('started_at'):
                report_lines.append(f"**å¼€å§‹æ—¶é—´**: {task['started_at']}")

            if task.get('completed_at'):
                report_lines.append(f"**å®Œæˆæ—¶é—´**: {task['completed_at']}")

            if result:
                # è¾“å‡ºæ‘˜è¦
                if result.get('summary'):
                    report_lines.append(f"\n**æ‰§è¡Œæ‘˜è¦**: {result['summary']}")

                # è¾“å‡ºæ•°æ®
                if result.get('output_data'):
                    report_lines.append(f"\n**è¾“å‡ºæ•°æ®**:")
                    for key, value in result['output_data'].items():
                        report_lines.append(f"- {key}: {value}")

                # é”™è¯¯ä¿¡æ¯
                if result.get('errors'):
                    report_lines.append(f"\n**é”™è¯¯ä¿¡æ¯**:")
                    for error in result['errors']:
                        report_lines.append(f"- âŒ {error}")

                # è­¦å‘Šä¿¡æ¯
                if result.get('warnings'):
                    report_lines.append(f"\n**è­¦å‘Šä¿¡æ¯**:")
                    for warning in result['warnings']:
                        report_lines.append(f"- âš ï¸ {warning}")

            # è¾“å‡ºæ–‡ä»¶è·¯å¾„
            report_lines.append(f"\n**è¾“å‡ºæ–‡ä»¶**: `{task['output_path']}`")
            report_lines.append("")

        # å¤±è´¥ä»»åŠ¡æ±‡æ€»
        if failed_tasks:
            report_lines.append("\n## âŒ å¤±è´¥ä»»åŠ¡æ±‡æ€»\n")
            for task in failed_tasks:
                task_id = task['task_id']
                result = results.get(task_id, {})
                report_lines.append(f"### {task_id}: {task['description']}")

                if result and result.get('errors'):
                    for error in result['errors']:
                        report_lines.append(f"- {error}")
                report_lines.append("")

        # æ€»ç»“
        report_lines.append("\n## ğŸ¯ æ€»ç»“\n")

        if len(completed_tasks) == len(tasks):
            report_lines.append("âœ… **æ‰€æœ‰ä»»åŠ¡å·²æˆåŠŸå®Œæˆ!**")
        elif failed_tasks:
            report_lines.append(f"âš ï¸ **éƒ¨åˆ†ä»»åŠ¡å¤±è´¥** ({len(failed_tasks)}/{len(tasks)})")
        elif pending_tasks:
            report_lines.append(f"â³ **éƒ¨åˆ†ä»»åŠ¡æœªå®Œæˆ** ({len(pending_tasks)}/{len(tasks)})")

        # ä¸‹ä¸€æ­¥å»ºè®®
        report_lines.append("\n### ä¸‹ä¸€æ­¥å»ºè®®\n")
        if failed_tasks:
            report_lines.append("1. æ£€æŸ¥å¤±è´¥ä»»åŠ¡çš„é”™è¯¯æ—¥å¿—")
            report_lines.append("2. ä¿®å¤é—®é¢˜åé‡æ–°æ‰§è¡Œå¤±è´¥ä»»åŠ¡")
        if pending_tasks:
            report_lines.append("1. æ£€æŸ¥æœªå®Œæˆä»»åŠ¡çš„çŠ¶æ€")
            report_lines.append("2. ç¡®è®¤Workeræ˜¯å¦æ­£å¸¸è¿è¡Œ")
        if len(completed_tasks) == len(tasks):
            report_lines.append("1. æŸ¥çœ‹å„é˜¶æ®µçš„è¾“å‡ºæ–‡ä»¶")
            report_lines.append("2. æ•´åˆæœ€ç»ˆäº¤ä»˜ç‰©")

        return "\n".join(report_lines)

    def _topological_sort(self, tasks: List[Dict]) -> List[Dict]:
        """
        æŒ‰ä¾èµ–å…³ç³»æ‹“æ‰‘æ’åºä»»åŠ¡

        Args:
            tasks: ä»»åŠ¡åˆ—è¡¨

        Returns:
            æ’åºåçš„ä»»åŠ¡åˆ—è¡¨
        """
        # æ„å»ºä¾èµ–å›¾
        task_dict = {task['task_id']: task for task in tasks}
        in_degree = {task['task_id']: 0 for task in tasks}

        # è®¡ç®—å…¥åº¦
        for task in tasks:
            for dep in task.get('dependencies', []):
                if dep in in_degree:
                    in_degree[task['task_id']] += 1

        # æ‹“æ‰‘æ’åº
        sorted_tasks = []
        queue = [tid for tid, degree in in_degree.items() if degree == 0]

        while queue:
            current_id = queue.pop(0)
            sorted_tasks.append(task_dict[current_id])

            # æ›´æ–°ä¾èµ–æ­¤ä»»åŠ¡çš„å…¶ä»–ä»»åŠ¡çš„å…¥åº¦
            for task in tasks:
                if current_id in task.get('dependencies', []):
                    in_degree[task['task_id']] -= 1
                    if in_degree[task['task_id']] == 0:
                        queue.append(task['task_id'])

        return sorted_tasks

    def _format_status(self, status: str) -> str:
        """æ ¼å¼åŒ–çŠ¶æ€æ˜¾ç¤º"""
        status_map = {
            'pending': 'â³ å¾…æ‰§è¡Œ',
            'running': 'ğŸ”„ æ‰§è¡Œä¸­',
            'completed': 'âœ… å·²å®Œæˆ',
            'failed': 'âŒ å·²å¤±è´¥'
        }
        return status_map.get(status, status)

    def generate_summary_report(self) -> Dict[str, Any]:
        """ç”ŸæˆJSONæ ¼å¼çš„æ‘˜è¦æŠ¥å‘Š"""
        tasks = self._load_all_tasks()
        results = {}

        for task in tasks:
            result = self._load_result(task['output_path'])
            if result:
                results[task['task_id']] = result

        completed_tasks = [t for t in tasks if t['status'] == 'completed']
        failed_tasks = [t for t in tasks if t['status'] == 'failed']

        summary = {
            "project_name": self.project_name,
            "generated_at": datetime.now().isoformat(),
            "total_tasks": len(tasks),
            "completed_tasks": len(completed_tasks),
            "failed_tasks": len(failed_tasks),
            "success_rate": len(completed_tasks) / len(tasks) if tasks else 0,
            "tasks": [
                {
                    "task_id": task['task_id'],
                    "description": task['description'],
                    "status": task['status'],
                    "has_result": task['task_id'] in results
                }
                for task in tasks
            ]
        }

        return summary


def main():
    """å‘½ä»¤è¡Œæµ‹è¯•å…¥å£"""
    import sys

    if len(sys.argv) < 2:
        print("Usage: python result_aggregator.py <project_name> [--monitor]")
        sys.exit(1)

    project_name = sys.argv[1]
    monitor_mode = '--monitor' in sys.argv

    aggregator = ResultAggregator(project_name=project_name)

    if monitor_mode:
        # ç›‘æ§æ¨¡å¼: æŒç»­ç›‘æ§å¹¶ç”ŸæˆæŠ¥å‘Š
        report_path = aggregator.monitor_and_aggregate(
            check_interval=10,
            max_wait_time=3600
        )
        print(f"\nâœ… æœ€ç»ˆæŠ¥å‘Š: {report_path}")
    else:
        # ä¸€æ¬¡æ€§ç”ŸæˆæŠ¥å‘Š
        tasks = aggregator._load_all_tasks()
        results = {}

        for task in tasks:
            result = aggregator._load_result(task['output_path'])
            if result:
                results[task['task_id']] = result

        report = aggregator._generate_report(tasks, results)

        with open(aggregator.report_path, 'w', encoding='utf-8') as f:
            f.write(report)

        print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {aggregator.report_path}")


if __name__ == "__main__":
    main()
