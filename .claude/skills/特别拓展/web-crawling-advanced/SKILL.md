---
name: web-crawling-advanced
description: åŸºäºCrawlee-Pythonçš„ä¼ä¸šçº§ç½‘é¡µçˆ¬è™«æ¡†æ¶ï¼Œæ”¯æŒé™æ€å’ŒåŠ¨æ€ç½‘é¡µé‡‡é›†ã€ååçˆ¬æœºåˆ¶ã€ä»£ç†è½®æ¢ã€æ•°æ®æŒä¹…åŒ–ï¼Œé€‚ç”¨äºç«å“ç›‘æ§ã€å¸‚åœºè°ƒç ”ã€æ•°æ®é‡‡é›†ç­‰åœºæ™¯
---

# Web Crawling Advanced Skill

> ä¼ä¸šçº§Pythonçˆ¬è™«æ¡†æ¶ï¼ŒåŸºäºCrawlee v1.0.3
> é€‚ç”¨æ™ºèƒ½ä½“ï¼šE2-ç½‘ç«™æƒ…æŠ¥é‡‡é›†å‘˜ã€E3-ç½‘ç«™æ·±åº¦çˆ¬è™«å‘˜ã€G4-ç«äº‰æƒ…æŠ¥åˆ†æå¸ˆ

---

## ğŸš€ Quick Start

### åŸºç¡€ç”¨æ³• - é™æ€ç½‘é¡µé‡‡é›†

```python
from skills.web_crawling_advanced.scripts.crawlee_engine import ZTLCrawler
import asyncio

async def quick_crawl():
    """å¿«é€Ÿé‡‡é›†é™æ€ç½‘é¡µ"""

    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    crawler = ZTLCrawler(crawler_type='beautifulsoup')

    # å®šä¹‰æ•°æ®æå–é€»è¾‘
    async def handler(context):
        return {
            'url': context.request.url,
            'title': context.soup.find('title').get_text() if context.soup.find('title') else '',
            'text': context.soup.get_text()[:500]  # å‰500å­—ç¬¦
        }

    # æ‰§è¡Œçˆ¬å–
    results = await crawler.crawl(['https://example.com'], handler)

    # å¯¼å‡ºç»“æœ
    await crawler.export_data('output/æƒ…æŠ¥ç»„/crawl-results.json')

    return results

# è¿è¡Œ
asyncio.run(quick_crawl())
```

### è¿›é˜¶ç”¨æ³• - åŠ¨æ€ç½‘é¡µé‡‡é›†

```python
async def dynamic_crawl():
    """é‡‡é›†éœ€è¦JavaScriptæ¸²æŸ“çš„åŠ¨æ€ç½‘é¡µ"""

    # ä½¿ç”¨Playwrightå¼•æ“
    crawler = ZTLCrawler(
        crawler_type='playwright',
        headless=True,
        max_requests=50
    )

    async def handler(context):
        page = context.page

        # ç­‰å¾…å†…å®¹åŠ è½½
        await page.wait_for_selector('.content')

        # æå–æ•°æ®
        return {
            'url': context.request.url,
            'title': await page.title(),
            'content': await page.inner_text('.content')
        }

    results = await crawler.crawl(['https://dynamic-site.com'], handler)
    return results
```

---

## ğŸ“‹ æ ¸å¿ƒåŠŸèƒ½

### âœ… æ”¯æŒçš„çˆ¬è™«ç±»å‹

| çˆ¬è™«ç±»å‹ | é€‚ç”¨åœºæ™¯ | æ€§èƒ½ | åŠŸèƒ½ |
|---------|---------|------|------|
| **BeautifulSoupCrawler** | é™æ€HTMLç½‘é¡µ | âš¡âš¡âš¡ æå¿« | åŸºç¡€ |
| **PlaywrightCrawler** | åŠ¨æ€JavaScriptæ¸²æŸ“ | âš¡âš¡ ä¸­ç­‰ | å®Œæ•´ |
| **AdaptivePlaywrightCrawler** | æ™ºèƒ½è‡ªé€‚åº” | âš¡âš¡ ä¸­ç­‰ | æ™ºèƒ½ |

### âœ… æ ¸å¿ƒç‰¹æ€§

- ğŸ›¡ï¸ **ååçˆ¬ä¿æŠ¤**: çœŸå®æµè§ˆå™¨æŒ‡çº¹ã€User-Agentè½®æ¢
- ğŸ”„ **è‡ªåŠ¨é‡è¯•**: è¯·æ±‚å¤±è´¥è‡ªåŠ¨é‡è¯•ï¼Œæ”¯æŒè‡ªå®šä¹‰ç­–ç•¥
- ğŸ’¾ **æ•°æ®æŒä¹…åŒ–**: æ”¯æŒæš‚åœ/æ¢å¤ï¼ŒçŠ¶æ€è‡ªåŠ¨ä¿å­˜
- ğŸ“Š **å¤šæ ¼å¼å¯¼å‡º**: JSONã€CSVã€Excel
- ğŸš€ **è‡ªåŠ¨å¹¶å‘**: æ ¹æ®ç³»ç»Ÿèµ„æºè‡ªåŠ¨è°ƒæ•´å¹¶å‘æ•°
- ğŸ”— **æ™ºèƒ½é“¾æ¥å‘ç°**: è‡ªåŠ¨å‘ç°å’Œçˆ¬å–å…³è”é“¾æ¥

---

## ğŸ¯ å…¸å‹åº”ç”¨åœºæ™¯

### åœºæ™¯1: ç«å“èœå•ç›‘æ§

```python
from skills.web_crawling_advanced.scripts.crawlee_engine import crawl_competitor_menu

# ä¸€è¡Œä»£ç ç›‘æ§ç«å“èœå•
results = await crawl_competitor_menu('https://www.meituan.com/meishi/123456')
```

### åœºæ™¯2: æ‰¹é‡é‡‡é›†é¤å…è¯„ä»·

```python
from skills.web_crawling_advanced.scripts.crawlee_engine import crawl_reviews

# æ‰¹é‡é‡‡é›†å¤šå®¶é¤å…è¯„ä»·
restaurant_urls = [
    'https://www.dianping.com/shop/1',
    'https://www.dianping.com/shop/2',
    # ... æ›´å¤šURL
]

reviews = await crawl_reviews(restaurant_urls, max_reviews_per_restaurant=100)
```

### åœºæ™¯3: è¡Œä¸šæ•°æ®å®šæœŸé‡‡é›†

```python
from skills.web_crawling_advanced.scripts.crawlee_engine import schedule_crawl

# æ¯å¤©è‡ªåŠ¨é‡‡é›†è¡Œä¸šæ–°é—»
await schedule_crawl(
    urls=['https://industry-news.com'],
    handler=news_handler,
    schedule='0 9 * * *',  # æ¯å¤©9ç‚¹
    output_path='output/æƒ…æŠ¥ç»„/daily-news/'
)
```

---

## ğŸ› ï¸ API Reference

### ZTLCrawlerç±»

**åˆå§‹åŒ–å‚æ•°**:
```python
crawler = ZTLCrawler(
    crawler_type='beautifulsoup',  # 'beautifulsoup' | 'playwright' | 'adaptive'
    headless=True,                 # æ— å¤´æ¨¡å¼ï¼ˆä»…Playwrightï¼‰
    max_requests=100,              # æœ€å¤§è¯·æ±‚æ•°
    proxy_config=None,             # ä»£ç†é…ç½®
    retry_config=None              # é‡è¯•é…ç½®
)
```

**æ ¸å¿ƒæ–¹æ³•**:
- `crawl(urls, handler)`: æ‰§è¡Œçˆ¬å–ä»»åŠ¡
- `export_data(output_path, format='json')`: å¯¼å‡ºæ•°æ®
- `get_stats()`: è·å–çˆ¬å–ç»Ÿè®¡ä¿¡æ¯

è¯¦ç»†APIæ–‡æ¡£è¯·å‚è€ƒ [reference.md](./reference.md)

---

## ğŸ“¦ ä¾èµ–å®‰è£…

```bash
# å®‰è£…Crawleeå’Œæ‰€æœ‰ä¾èµ–
pip install 'crawlee[all]'

# å®‰è£…Playwrightæµè§ˆå™¨é©±åŠ¨
playwright install chromium
```

---

## ğŸ”— ç›¸å…³èµ„æº

- **å®˜æ–¹æ–‡æ¡£**: https://crawlee.dev/python/
- **GitHubä»“åº“**: https://github.com/apify/crawlee-python
- **ç¤ºä¾‹ä»£ç **: [examples/](./examples/)
- **æ‰©å±•æ–‡æ¡£**: [reference.md](./reference.md)

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **åˆè§„ä½¿ç”¨**: è¯·éµå®ˆç½‘ç«™robots.txtå’ŒæœåŠ¡æ¡æ¬¾
2. **é€Ÿç‡é™åˆ¶**: å»ºè®®è®¾ç½®åˆç†çš„è¯·æ±‚é—´éš”ï¼Œé¿å…å¯¹ç›®æ ‡æœåŠ¡å™¨é€ æˆå‹åŠ›
3. **æ•°æ®éšç§**: é‡‡é›†çš„æ•°æ®ä»…ç”¨äºä¸šåŠ¡åˆ†æï¼Œä¸å¾—ç”¨äºéæ³•ç”¨é€”
4. **èµ„æºå ç”¨**: Playwrightçˆ¬è™«å ç”¨è¾ƒå¤šå†…å­˜ï¼Œå»ºè®®å•æ¬¡çˆ¬å–ä¸è¶…è¿‡1000é¡µ

---

**ç‰ˆæœ¬**: v1.0.0
**æœ€åæ›´æ–°**: 2025-10-21
**ç»´æŠ¤è€…**: ZTLæ•°æ™ºåŒ–ä½œæˆ˜ä¸­å¿ƒ-æƒ…æŠ¥ç»„
