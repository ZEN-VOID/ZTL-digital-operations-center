#!/usr/bin/env python3
"""
Nano-Banana AIGC æ ¸å¿ƒæ‰§è¡Œå¼•æ“ v2.0
====================================
åŸºäº Google Gemini 2.5 Flash Image (OpenRouter)
æ”¯æŒ9ç§å›¾ç‰‡å¤„ç†å·¥ä½œæµ,æ¯ç§å·¥ä½œæµéƒ½æœ‰ä¸“å±æç¤ºè¯ä¼˜åŒ–ç­–ç•¥

å·¥ä½œæµçŸ©é˜µ:
1. æ–‡ç”Ÿå›¾ (text-to-image)
2. é£æ ¼å‚è€ƒç”Ÿå›¾ (style-reference)
3. ä¸»ä½“å‚è€ƒç”Ÿå›¾ (subject-reference)
4. èƒŒæ™¯æ›¿æ¢ (background-replace)
5. ä¸»ä½“æ›¿æ¢ (subject-replace)
6. å±€éƒ¨ä¿®æ”¹ (local-edit)
7. è°ƒæ•´åŠ¨ä½œ/è§’åº¦/ç©ºé—´ (pose-angle-space)
8. é£æ ¼è½¬ç»˜ (style-transfer)
9. æç¤ºè¯ä¼˜åŒ–å™¨ (è‡ªåŠ¨é›†æˆåˆ°æ‰€æœ‰å·¥ä½œæµ)
"""

import base64
import json
import os
import requests
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import List, Literal, Optional, Dict, Any


# ============================================
# ç¯å¢ƒå˜é‡åŠ è½½
# ============================================

def load_env_from_root():
    """ä»é¡¹ç›®æ ¹ç›®å½•çš„ .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡"""
    current_dir = Path(__file__).resolve()
    for parent in [current_dir] + list(current_dir.parents):
        env_file = parent / ".env"
        if env_file.exists():
            with open(env_file, "r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if not line or line.startswith("#"):
                        continue
                    if "=" in line:
                        key, value = line.split("=", 1)
                        key = key.strip()
                        value = value.strip()
                        if key not in os.environ:
                            os.environ[key] = value
            return True
    return False


load_env_from_root()


# ============================================
# é…ç½®å’Œæ•°æ®ç±»
# ============================================

@dataclass
class ImageConfig:
    """å›¾åƒç”Ÿæˆé…ç½®"""
    aspect_ratio: str = "1:1"  # 1:1, 16:9, 4:3, 3:2, 2:3, 3:4, 9:16, 21:9
    max_tokens: int = 8192
    temperature: float = 1.0
    top_p: float = 0.95
    seed: Optional[int] = None


@dataclass
class PromptOptimizationConfig:
    """æç¤ºè¯ä¼˜åŒ–é…ç½®"""
    task_type: Literal[
        "text-to-image",
        "style-reference",
        "subject-reference",
        "background-replace",
        "subject-replace",
        "local-edit",
        "pose-angle-space",
        "style-transfer"
    ]
    context: str  # ä¸šåŠ¡åœºæ™¯æè¿° (å¦‚: "é¤é¥®è¡Œä¸šæµ·æŠ¥è®¾è®¡")
    target_style: Optional[str] = None  # ç›®æ ‡é£æ ¼
    requirements: List[str] = field(default_factory=list)  # ç‰¹æ®Šè¦æ±‚åˆ—è¡¨


@dataclass
class ImageInput:
    """å›¾åƒè¾“å…¥"""
    path: Optional[str] = None  # æœ¬åœ°è·¯å¾„
    url: Optional[str] = None  # ç½‘ç»œURL
    base64_data: Optional[str] = None  # Base64ç¼–ç 
    description: Optional[str] = None  # å›¾åƒæè¿°


# ============================================
# æç¤ºè¯ä¼˜åŒ–å¼•æ“ v2.0 (9ç§å·¥ä½œæµä¸“å±ä¼˜åŒ–)
# ============================================

class PromptOptimizer:
    """
    æç¤ºè¯è‡ªåŠ¨ä¼˜åŒ–å¼•æ“ v2.0
    ä¸º9ç§å›¾ç‰‡å¤„ç†å·¥ä½œæµæä¾›ä¸“å±ä¼˜åŒ–ç­–ç•¥
    """

    # æ‘„å½±æœ¯è¯­åº“
    PHOTOGRAPHY_TERMS = {
        "lighting": [
            "golden hour light", "soft diffused lighting", "dramatic side lighting",
            "three-point lighting", "softbox setup", "natural window light"
        ],
        "lens": [
            "85mm portrait lens", "24mm wide-angle", "macro lens",
            "50mm prime", "telephoto zoom"
        ],
        "shot_type": [
            "close-up", "medium shot", "wide shot", "bird's eye view",
            "45-degree angle", "overhead shot"
        ],
        "depth": [
            "shallow depth of field", "bokeh background", "f/2.8 aperture",
            "sharp focus", "natural depth"
        ]
    }

    # è®¾è®¡é£æ ¼åº“
    DESIGN_STYLES = {
        "photorealistic": (
            "ultra-realistic commercial photography, 8K resolution, "
            "shot on medium format camera, professional studio lighting, "
            "high dynamic range, physical material textures, "
            "NOT illustration, NOT CGI, authentic photographic quality"
        ),
        "æ°´å½©": "watercolor painting style, soft edges, flowing colors, artistic brush strokes",
        "å¡é€š": "kawaii cartoon style, bold outlines, vibrant colors, cute aesthetic",
        "ç®€çº¦": "minimalist design, clean lines, negative space, modern aesthetic",
        "å¤å¤": "vintage aesthetic, film grain, retro color grading, nostalgic mood"
    }

    # é¤é¥®è¡Œä¸šåœºæ™¯æ¨¡æ¿
    RESTAURANT_SCENARIOS = {
        "æµ·æŠ¥è®¾è®¡": {
            "keywords": ["æµ·æŠ¥", "poster", "å®£ä¼ "],
            "prefix": "Commercial restaurant promotional poster,",
            "suffix": "professional poster photography, billboard quality, high-resolution"
        },
        "èœå•æ‘„å½±": {
            "keywords": ["èœå•", "menu", "èœå“"],
            "prefix": "Professional restaurant menu photography,",
            "suffix": "appetizing presentation, three-point lighting, Michelin-star quality"
        },
        "ç¤¾äº¤åª’ä½“": {
            "keywords": ["æœ‹å‹åœˆ", "ç¤¾äº¤", "social", "æŠ–éŸ³"],
            "prefix": "Eye-catching social media restaurant content,",
            "suffix": "Instagram-worthy, mobile-optimized, shareable aesthetic"
        },
        "äº§å“å›¾": {
            "keywords": ["äº§å“", "å•†å“", "å±•ç¤º"],
            "prefix": "Professional product photography,",
            "suffix": "clean background, studio lighting, commercial quality"
        }
    }

    def optimize(
        self,
        user_prompt: str,
        config: PromptOptimizationConfig
    ) -> str:
        """
        ä¼˜åŒ–ç”¨æˆ·æç¤ºè¯

        Args:
            user_prompt: ç”¨æˆ·åŸå§‹è¾“å…¥
            config: ä¼˜åŒ–é…ç½®

        Returns:
            ä¼˜åŒ–åçš„æç¤ºè¯
        """
        # æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©ä¼˜åŒ–ç­–ç•¥
        task_type = config.task_type

        if task_type == "text-to-image":
            return self._optimize_text_to_image(user_prompt, config)
        elif task_type == "style-reference":
            return self._optimize_style_reference(user_prompt, config)
        elif task_type == "subject-reference":
            return self._optimize_subject_reference(user_prompt, config)
        elif task_type == "background-replace":
            return self._optimize_background_replace(user_prompt, config)
        elif task_type == "subject-replace":
            return self._optimize_subject_replace(user_prompt, config)
        elif task_type == "local-edit":
            return self._optimize_local_edit(user_prompt, config)
        elif task_type == "pose-angle-space":
            return self._optimize_pose_angle_space(user_prompt, config)
        elif task_type == "style-transfer":
            return self._optimize_style_transfer(user_prompt, config)
        else:
            return self._enhance_description(user_prompt)

    # ========== 1. æ–‡ç”Ÿå›¾ä¼˜åŒ–ç­–ç•¥ ==========
    def _optimize_text_to_image(
        self,
        user_prompt: str,
        config: PromptOptimizationConfig
    ) -> str:
        """æ–‡ç”Ÿå›¾: Subject + Composition + Style + Lighting + Colors + Quality"""
        parts = []

        # 1. é¤é¥®åœºæ™¯å‰ç¼€
        scenario = self._detect_restaurant_scenario(user_prompt)
        if scenario:
            template = self.RESTAURANT_SCENARIOS[scenario]
            parts.append(template["prefix"])

        # 2. å¢å¼ºç”¨æˆ·æè¿°
        parts.append(self._enhance_description(user_prompt))

        # 3. é£æ ¼æœ¯è¯­
        if config.target_style:
            style_key = self._map_style_key(config.target_style)
            if style_key in self.DESIGN_STYLES:
                parts.append(self.DESIGN_STYLES[style_key])
            else:
                parts.append(config.target_style)

        # 4. æ‘„å½±æŠ€æœ¯ç»†èŠ‚
        if config.target_style and "æ‘„å½±" in config.target_style:
            parts.extend([
                self.PHOTOGRAPHY_TERMS["lighting"][0],
                self.PHOTOGRAPHY_TERMS["lens"][0],
                self.PHOTOGRAPHY_TERMS["depth"][0]
            ])

        # 5. ç‰¹æ®Šè¦æ±‚
        if config.requirements:
            parts.extend(config.requirements)

        # 6. é¤é¥®åœºæ™¯åç¼€
        if scenario:
            parts.append(self.RESTAURANT_SCENARIOS[scenario]["suffix"])

        return ", ".join(filter(None, parts))

    # ========== 2. é£æ ¼å‚è€ƒç”Ÿå›¾ä¼˜åŒ–ç­–ç•¥ ==========
    def _optimize_style_reference(
        self,
        user_prompt: str,
        config: PromptOptimizationConfig
    ) -> str:
        """é£æ ¼å‚è€ƒ: é£æ ¼ç‰¹å¾æå– + é£æ ¼ä¸€è‡´æ€§æŒ‡ä»¤"""
        parts = [
            "Match the visual style of the reference image exactly,",
            "preserve color palette, composition style, texture quality,",
            user_prompt,
            "maintain brand consistency, style coherence priority"
        ]
        return " ".join(parts)

    # ========== 3. ä¸»ä½“å‚è€ƒç”Ÿå›¾ä¼˜åŒ–ç­–ç•¥ ==========
    def _optimize_subject_reference(
        self,
        user_prompt: str,
        config: PromptOptimizationConfig
    ) -> str:
        """ä¸»ä½“å‚è€ƒ: ä¸»ä½“ç‰¹å¾é”å®š + åœºæ™¯èåˆ"""
        parts = [
            "Keep the subject character/object from reference image EXACTLY the same,",
            "preserve all visual features (appearance, clothing, details),",
            user_prompt,
            "natural scene integration, consistent lighting with environment,",
            "character/product consistency is critical priority"
        ]
        return " ".join(parts)

    # ========== 4. èƒŒæ™¯æ›¿æ¢ä¼˜åŒ–ç­–ç•¥ ==========
    def _optimize_background_replace(
        self,
        user_prompt: str,
        config: PromptOptimizationConfig
    ) -> str:
        """èƒŒæ™¯æ›¿æ¢: ä¸»ä½“ä¿æŠ¤ + æ–°èƒŒæ™¯æè¿° + å…‰ç…§ä¸€è‡´æ€§"""
        parts = [
            "Preserve the main subject completely unchanged (keep all details intact),",
            f"replace background with: {user_prompt},",
            "seamless lighting transition between subject and new background,",
            "natural compositing, realistic integration, coherent atmosphere"
        ]
        return " ".join(parts)

    # ========== 5. ä¸»ä½“æ›¿æ¢ä¼˜åŒ–ç­–ç•¥ ==========
    def _optimize_subject_replace(
        self,
        user_prompt: str,
        config: PromptOptimizationConfig
    ) -> str:
        """ä¸»ä½“æ›¿æ¢: èƒŒæ™¯ä¿æŠ¤ + æ–°ä¸»ä½“æè¿° + é€è§†ä¸€è‡´æ€§"""
        parts = [
            "Preserve the background environment completely unchanged,",
            f"replace the main subject with: {user_prompt},",
            "maintain consistent lighting and perspective with original scene,",
            "natural integration, realistic shadows and reflections"
        ]
        return " ".join(parts)

    # ========== 6. å±€éƒ¨ä¿®æ”¹ä¼˜åŒ–ç­–ç•¥ ==========
    def _optimize_local_edit(
        self,
        user_prompt: str,
        config: PromptOptimizationConfig
    ) -> str:
        """å±€éƒ¨ä¿®æ”¹: ç²¾ç¡®åŒºåŸŸå®šä½ + ä¿æŠ¤éä¿®æ”¹åŒº + è‡ªç„¶è¿‡æ¸¡"""
        parts = [
            f"Precisely edit the specified region: {user_prompt},",
            "keep ALL other elements completely unchanged,",
            "seamless transition with surrounding areas,",
            "natural blending, invisible editing, preserve original quality"
        ]
        return " ".join(parts)

    # ========== 7. åŠ¨ä½œ/è§’åº¦/ç©ºé—´è°ƒæ•´ä¼˜åŒ–ç­–ç•¥ ==========
    def _optimize_pose_angle_space(
        self,
        user_prompt: str,
        config: PromptOptimizationConfig
    ) -> str:
        """åŠ¨ä½œ/è§’åº¦/ç©ºé—´: è§†è§’å˜æ¢ + ä¸»ä½“ä¸€è‡´æ€§ + ç‰©ç†åˆç†æ€§"""
        parts = [
            "Keep the subject's appearance, textures, colors EXACTLY the same,",
            f"adjust the pose/angle/spatial relationship: {user_prompt},",
            "maintain consistent lighting direction and quality,",
            "physically plausible transformation, realistic shadows and perspective"
        ]
        return " ".join(parts)

    # ========== 8. é£æ ¼è½¬ç»˜ä¼˜åŒ–ç­–ç•¥ ==========
    def _optimize_style_transfer(
        self,
        user_prompt: str,
        config: PromptOptimizationConfig
    ) -> str:
        """é£æ ¼è½¬ç»˜: é£æ ¼è¯¦ç»†æè¿° + å†…å®¹ä¿ç•™ + é£æ ¼åŒ–ç¨‹åº¦"""
        target_style = config.target_style or "artistic style"

        # è¯¦ç»†é£æ ¼æè¿°
        style_details = self.DESIGN_STYLES.get(
            self._map_style_key(target_style),
            target_style
        )

        parts = [
            f"Transform the image to {style_details},",
            "preserve ALL scene content and composition structure,",
            user_prompt,
            "maintain recognizability of original subjects,",
            "balanced stylization level, artistic yet coherent"
        ]
        return " ".join(parts)

    # ========== è¾…åŠ©æ–¹æ³• ==========

    def _enhance_description(self, prompt: str) -> str:
        """å¢å¼ºæè¿°çš„å…·ä½“æ€§"""
        if len(prompt) < 20:
            return f"{prompt}, detailed scene description, specific visual characteristics"
        return prompt

    def _detect_restaurant_scenario(self, prompt: str) -> Optional[str]:
        """æ£€æµ‹é¤é¥®åœºæ™¯ç±»å‹ (ä¼˜å…ˆçº§: ç¤¾äº¤åª’ä½“ > èœå• > äº§å“ > æµ·æŠ¥)"""
        for scenario_name, scenario_data in self.RESTAURANT_SCENARIOS.items():
            if any(kw in prompt for kw in scenario_data["keywords"]):
                return scenario_name
        return None

    def _map_style_key(self, style: str) -> str:
        """æ˜ å°„é£æ ¼æè¿°åˆ°æ ·å¼é”®"""
        mapping = {
            "æ‘„å½±": "photorealistic",
            "å†™å®": "photorealistic",
            "æ°´å½©": "æ°´å½©",
            "å¡é€š": "å¡é€š",
            "ç®€çº¦": "ç®€çº¦",
            "å¤å¤": "å¤å¤"
        }
        for zh, key in mapping.items():
            if zh in style:
                return key
        return style


# ============================================
# ä»»åŠ¡ç±»å‹æ¨èé…ç½®
# ============================================

TASK_TYPE_CONFIGS = {
    "text-to-image": {
        "temperature": 1.0,
        "aspect_ratio": "16:9"
    },
    "style-reference": {
        "temperature": 0.8,  # é£æ ¼ä¸€è‡´æ€§éœ€è¦æ›´ä½æ¸©åº¦
        "aspect_ratio": None  # ç»§æ‰¿å‚è€ƒå›¾æ¯”ä¾‹
    },
    "subject-reference": {
        "temperature": 0.7,  # è§’è‰²ä¸€è‡´æ€§ä¼˜å…ˆ
        "aspect_ratio": None
    },
    "background-replace": {
        "temperature": 0.8,
        "aspect_ratio": None
    },
    "subject-replace": {
        "temperature": 0.8,
        "aspect_ratio": None
    },
    "local-edit": {
        "temperature": 0.6,  # ç²¾ç¡®ç¼–è¾‘éœ€è¦ä½æ¸©åº¦
        "aspect_ratio": None
    },
    "pose-angle-space": {
        "temperature": 0.7,
        "aspect_ratio": None
    },
    "style-transfer": {
        "temperature": 1.0,  # é£æ ¼è½¬æ¢å…è®¸æ›´é«˜åˆ›æ„åº¦
        "aspect_ratio": None
    }
}


# ============================================
# API å®¢æˆ·ç«¯
# ============================================

class NanoBananaClient:
    """
    Nano-Banana API å®¢æˆ·ç«¯
    å°è£… OpenRouter çš„ Google Gemini 2.5 Flash Image è°ƒç”¨
    """

    API_BASE = "https://openrouter.ai/api/v1"
    MODEL = "google/gemini-2.5-flash-image"

    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv("OPENROUTER_API_KEY")
        if not self.api_key:
            raise ValueError("æœªæ‰¾åˆ° OPENROUTER_API_KEY, è¯·è®¾ç½®ç¯å¢ƒå˜é‡æˆ–ä¼ å…¥å‚æ•°")

        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://github.com/anthropics/claude-code",
            "X-Title": "ZTL-Digital-Operations-Center-Nano-Banana-AIGC-v2"
        }

    def generate(
        self,
        prompt: str,
        images: Optional[List[ImageInput]] = None,
        config: Optional[ImageConfig] = None
    ) -> Dict[str, Any]:
        """ç”Ÿæˆå›¾åƒ"""
        if config is None:
            config = ImageConfig()

        # æ„å»ºæ¶ˆæ¯å†…å®¹
        content_parts = []

        # æ·»åŠ è¾“å…¥å›¾åƒ (å¦‚æœ‰)
        if images:
            for img in images:
                img_part = self._prepare_image_part(img)
                if img_part:
                    content_parts.append(img_part)
                    if img.description:
                        content_parts.append({
                            "type": "text",
                            "text": f"[Image context: {img.description}]"
                        })

        # æ·»åŠ æ–‡æœ¬æç¤ºè¯
        content_parts.append({
            "type": "text",
            "text": prompt
        })

        # æ„å»ºè¯·æ±‚ä½“
        payload = {
            "model": self.MODEL,
            "messages": [
                {
                    "role": "user",
                    "content": content_parts
                }
            ],
            "max_tokens": config.max_tokens,
            "temperature": config.temperature,
            "top_p": config.top_p
        }

        if config.seed is not None:
            payload["seed"] = config.seed

        # å‘é€è¯·æ±‚
        response = requests.post(
            f"{self.API_BASE}/chat/completions",
            headers=self.headers,
            json=payload,
            timeout=120
        )

        response.raise_for_status()
        return response.json()

    def _prepare_image_part(self, image_input: ImageInput) -> Optional[Dict[str, Any]]:
        """å‡†å¤‡å›¾åƒå†…å®¹éƒ¨åˆ†"""
        # ä¼˜å…ˆä½¿ç”¨ base64 æ•°æ®
        if image_input.base64_data:
            return {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{image_input.base64_data}"
                }
            }

        # æœ¬åœ°è·¯å¾„è½¬ base64
        if image_input.path:
            path = Path(image_input.path)
            if not path.exists():
                print(f"è­¦å‘Š: å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_input.path}")
                return None

            with open(path, "rb") as f:
                img_data = base64.b64encode(f.read()).decode("utf-8")

            mime_type = self._get_mime_type(path.suffix)
            return {
                "type": "image_url",
                "image_url": {
                    "url": f"data:{mime_type};base64,{img_data}"
                }
            }

        # URL å›¾åƒ
        if image_input.url:
            return {
                "type": "image_url",
                "image_url": {
                    "url": image_input.url
                }
            }

        return None

    @staticmethod
    def _get_mime_type(suffix: str) -> str:
        """æ ¹æ®æ–‡ä»¶åç¼€è·å– MIME ç±»å‹"""
        mime_map = {
            ".jpg": "image/jpeg",
            ".jpeg": "image/jpeg",
            ".png": "image/png",
            ".gif": "image/gif",
            ".webp": "image/webp"
        }
        return mime_map.get(suffix.lower(), "image/jpeg")


# ============================================
# å›¾åƒæå–å’Œä¿å­˜
# ============================================

class ImageExtractor:
    """ä» API å“åº”ä¸­æå–å’Œä¿å­˜å›¾åƒ"""

    @staticmethod
    def extract_image_from_response(response: Dict[str, Any]) -> Optional[str]:
        """
        ä» API å“åº”ä¸­æå–å›¾åƒæ•°æ®

        Returns:
            Base64 ç¼–ç çš„å›¾åƒæ•°æ® (ä¸å«å‰ç¼€)
        """
        try:
            choices = response.get("choices", [])
            if not choices:
                print("API å“åº”ä¸­æ²¡æœ‰ç”Ÿæˆå†…å®¹")
                return None

            message = choices[0].get("message", {})

            # ä¼˜å…ˆæ£€æŸ¥ images å­—æ®µ
            images = message.get("images", [])
            if images:
                image_url = images[0].get("image_url", {}).get("url", "")
                if image_url.startswith("data:image"):
                    return image_url.split(",", 1)[1]

            # å…¼å®¹æ—§æ ¼å¼: content å­—æ®µ
            content = message.get("content", "")
            if isinstance(content, str):
                import re
                img_pattern = r'!\[.*?\]\((data:image/[^;]+;base64,([^)]+))\)'
                matches = re.findall(img_pattern, content)
                if matches:
                    return matches[0][1]

                if content.startswith("data:image"):
                    return content.split(",", 1)[1]

            return None

        except Exception as e:
            print(f"æå–å›¾åƒå¤±è´¥: {e}")
            return None

    @staticmethod
    def save_image(
        base64_data: str,
        output_dir: Path,
        task_type: str,
        filename: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None
    ) -> Path:
        """
        ä¿å­˜å›¾åƒåˆ°æ–‡ä»¶

        Args:
            base64_data: Base64 ç¼–ç çš„å›¾åƒæ•°æ®
            output_dir: è¾“å‡ºç›®å½•
            task_type: ä»»åŠ¡ç±»å‹ (ç”¨äºæ–‡ä»¶å)
            filename: æ–‡ä»¶å (å¦‚æœªæä¾›åˆ™è‡ªåŠ¨ç”Ÿæˆ)
            metadata: å…ƒæ•°æ® (ä¿å­˜ä¸º JSON)

        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        output_dir.mkdir(parents=True, exist_ok=True)

        # ç”Ÿæˆæ–‡ä»¶å
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"nano_banana_{task_type}_{timestamp}.png"

        # ä¿å­˜å›¾åƒ
        img_path = output_dir / filename
        img_data = base64.b64decode(base64_data)
        img_path.write_bytes(img_data)

        # ä¿å­˜å…ƒæ•°æ®
        if metadata:
            meta_path = output_dir / f"{img_path.stem}_metadata.json"
            meta_path.write_text(json.dumps(metadata, ensure_ascii=False, indent=2))

        return img_path


# ============================================
# ç»Ÿä¸€ä»»åŠ¡æ‰§è¡Œå™¨
# ============================================

class NanoBananaExecutor:
    """
    Nano-Banana ç»Ÿä¸€ä»»åŠ¡æ‰§è¡Œå™¨ v2.0
    æ”¯æŒ9ç§å›¾ç‰‡å¤„ç†å·¥ä½œæµ,è‡ªåŠ¨æç¤ºè¯ä¼˜åŒ–
    """

    def __init__(self, api_key: Optional[str] = None):
        self.client = NanoBananaClient(api_key)
        self.optimizer = PromptOptimizer()
        self.extractor = ImageExtractor()

    def execute(
        self,
        user_prompt: str,
        task_type: str = "text-to-image",
        context: str = "",
        target_style: Optional[str] = None,
        requirements: Optional[List[str]] = None,
        images: Optional[List[ImageInput]] = None,
        config: Optional[ImageConfig] = None,
        output_dir: Optional[Path] = None,
        project_name: str = "æœªå‘½åé¡¹ç›®"
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„å›¾åƒç”Ÿæˆæµç¨‹

        Args:
            user_prompt: ç”¨æˆ·è¾“å…¥çš„æç¤ºè¯
            task_type: ä»»åŠ¡ç±»å‹ (æ”¯æŒ9ç§å·¥ä½œæµ)
            context: ä¸šåŠ¡åœºæ™¯ä¸Šä¸‹æ–‡
            target_style: ç›®æ ‡é£æ ¼
            requirements: ç‰¹æ®Šè¦æ±‚åˆ—è¡¨
            images: è¾“å…¥å›¾åƒåˆ—è¡¨
            config: ç”Ÿæˆé…ç½®
            output_dir: è¾“å‡ºç›®å½•
            project_name: é¡¹ç›®åç§°

        Returns:
            æ‰§è¡Œç»“æœ
        """
        # éªŒè¯ task_type
        valid_types = [
            "text-to-image", "style-reference", "subject-reference",
            "background-replace", "subject-replace", "local-edit",
            "pose-angle-space", "style-transfer"
        ]
        if task_type not in valid_types:
            raise ValueError(f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {task_type}. æ”¯æŒçš„ç±»å‹: {valid_types}")

        # 1. è‡ªåŠ¨åº”ç”¨æ¨èé…ç½®
        if config is None:
            config = ImageConfig()
            recommended = TASK_TYPE_CONFIGS.get(task_type, {})
            if "temperature" in recommended:
                config.temperature = recommended["temperature"]
            if "aspect_ratio" in recommended and recommended["aspect_ratio"]:
                config.aspect_ratio = recommended["aspect_ratio"]

        # 2. æç¤ºè¯ä¼˜åŒ–
        opt_config = PromptOptimizationConfig(
            task_type=task_type,
            context=context,
            target_style=target_style,
            requirements=requirements or []
        )
        optimized_prompt = self.optimizer.optimize(user_prompt, opt_config)

        print(f"[ä»»åŠ¡ç±»å‹] {task_type}")
        print(f"[åŸå§‹æç¤ºè¯] {user_prompt}")
        print(f"[ä¼˜åŒ–åæç¤ºè¯] {optimized_prompt}")
        print("-" * 80)

        # 3. API è°ƒç”¨
        print("æ­£åœ¨è°ƒç”¨ Nano-Banana API...")
        response = self.client.generate(
            prompt=optimized_prompt,
            images=images,
            config=config
        )

        # 4. æå–å›¾åƒ
        base64_data = self.extractor.extract_image_from_response(response)
        if not base64_data:
            return {
                "success": False,
                "error": "æœªèƒ½ä»å“åº”ä¸­æå–å›¾åƒ",
                "response": response
            }

        # 5. ä¿å­˜å›¾åƒ
        if output_dir is None:
            # æ ‡å‡†åŒ–è¾“å‡ºè·¯å¾„: output/[é¡¹ç›®å]/nano-banana/results/
            output_dir = Path("output") / project_name / "nano-banana" / "results"

        metadata = {
            "task_type": task_type,
            "original_prompt": user_prompt,
            "optimized_prompt": optimized_prompt,
            "context": context,
            "target_style": target_style,
            "requirements": requirements,
            "input_images": [img.path for img in (images or []) if img.path],
            "config": {
                "aspect_ratio": config.aspect_ratio,
                "temperature": config.temperature,
                "max_tokens": config.max_tokens,
                "seed": config.seed
            },
            "timestamp": datetime.now().isoformat(),
            "model": NanoBananaClient.MODEL,
            "api_usage": response.get("usage", {})
        }

        img_path = self.extractor.save_image(
            base64_data=base64_data,
            output_dir=output_dir,
            task_type=task_type,
            metadata=metadata
        )

        print(f"âœ… å›¾åƒå·²ä¿å­˜åˆ°: {img_path}")
        print(f"ğŸ“Š å…ƒæ•°æ®: {img_path.parent / f'{img_path.stem}_metadata.json'}")

        return {
            "success": True,
            "image_path": str(img_path),
            "task_type": task_type,
            "optimized_prompt": optimized_prompt,
            "metadata": metadata
        }


# ============================================
# å‘½ä»¤è¡Œæ¥å£ (ä¾›æµ‹è¯•ä½¿ç”¨)
# ============================================

def main():
    """å‘½ä»¤è¡Œæµ‹è¯•æ¥å£"""
    import argparse

    parser = argparse.ArgumentParser(
        description="Nano-Banana AIGC æ ¸å¿ƒå¼•æ“ v2.0 - 9ç§å›¾ç‰‡å¤„ç†å·¥ä½œæµ"
    )
    parser.add_argument("prompt", help="å›¾åƒç”Ÿæˆæç¤ºè¯")
    parser.add_argument(
        "--type",
        default="text-to-image",
        choices=[
            "text-to-image", "style-reference", "subject-reference",
            "background-replace", "subject-replace", "local-edit",
            "pose-angle-space", "style-transfer"
        ],
        help="ä»»åŠ¡ç±»å‹"
    )
    parser.add_argument("--context", default="", help="ä¸šåŠ¡åœºæ™¯ä¸Šä¸‹æ–‡")
    parser.add_argument("--style", help="ç›®æ ‡é£æ ¼")
    parser.add_argument("--image", action="append", help="è¾“å…¥å›¾åƒè·¯å¾„ (å¯å¤šæ¬¡æŒ‡å®š)")
    parser.add_argument("--output", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--project", default="æµ‹è¯•é¡¹ç›®", help="é¡¹ç›®åç§°")

    args = parser.parse_args()

    # å‡†å¤‡è¾“å…¥å›¾åƒ
    images = None
    if args.image:
        images = [ImageInput(path=img_path) for img_path in args.image]

    executor = NanoBananaExecutor()
    result = executor.execute(
        user_prompt=args.prompt,
        task_type=args.type,
        context=args.context,
        target_style=args.style,
        images=images,
        output_dir=Path(args.output) if args.output else None,
        project_name=args.project
    )

    if result["success"]:
        print(f"\nâœ¨ æˆåŠŸç”Ÿæˆå›¾åƒ!")
        print(f"ğŸ“ æ–‡ä»¶ä½ç½®: {result['image_path']}")
        print(f"ğŸ¯ ä»»åŠ¡ç±»å‹: {result['task_type']}")
    else:
        print(f"\nâŒ ç”Ÿæˆå¤±è´¥: {result.get('error')}")


if __name__ == "__main__":
    main()
