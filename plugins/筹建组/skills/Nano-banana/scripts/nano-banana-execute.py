#!/usr/bin/env python3
"""
Nano Banana Execute Engine - E5æ‰§è¡Œå¼•æ“
åŸºäºJSONæ‰§è¡Œè®¡åˆ’è‡ªåŠ¨åŒ–æ‰¹é‡ç”ŸæˆE5è¡ç”Ÿå›¾åƒ

æ ¸å¿ƒåŠŸèƒ½ï¼š
- åŠ è½½å’ŒéªŒè¯JSONæ‰§è¡Œè®¡åˆ’
- æ‰¹é‡å¤„ç†ä»»åŠ¡ï¼ˆ25ä¸ª/æ‰¹ï¼Œ5å¹¶å‘ï¼‰
- Checkpointæœºåˆ¶ï¼ˆæ¯10å¼ ä¿å­˜è¿›åº¦ï¼‰
- æŒ‡æ•°é€€é¿é‡è¯•ç­–ç•¥ï¼ˆ2s, 4s, 8sï¼‰
- è´¨é‡æ£€æŸ¥å’Œå…ƒæ•°æ®ç”Ÿæˆ

ä½¿ç”¨æ–¹æ³•:
  python nano-banana-execute.py --plan api/plans/nano-banana/e5-derivative-generation-20251012.json
"""

import sys
import json
import argparse
import asyncio
import time
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional
import yaml

# åŠ¨æ€å¯¼å…¥nano-banana-baseæ¨¡å—
api_file_path = Path(__file__).parent / "nano-banana-base.py"
import importlib.util
spec = importlib.util.spec_from_file_location("nano_banana_base", api_file_path)
banana_module = importlib.util.module_from_spec(spec)
sys.modules["nano_banana_base"] = banana_module
spec.loader.exec_module(banana_module)
NanoBananaAPI = banana_module.NanoBananaAPI


class E5ExecutionEngine:
    """E5æ‰§è¡Œå¼•æ“ - æ‰¹é‡è¡ç”Ÿå›¾ç”Ÿæˆ"""

    def __init__(self, plan_path: str):
        """
        åˆå§‹åŒ–æ‰§è¡Œå¼•æ“

        Args:
            plan_path: æ‰§è¡Œè®¡åˆ’JSONæ–‡ä»¶è·¯å¾„
        """
        self.plan_path = Path(plan_path)
        self.plan = None
        self.api = NanoBananaAPI()

        # æ‰§è¡ŒçŠ¶æ€
        self.total_tasks = 0
        self.completed_tasks = 0
        self.failed_tasks = 0
        self.execution_log = []

        # Checkpoint
        self.checkpoint_data = {
            "completed_task_ids": [],
            "failed_task_ids": [],
            "last_update": None
        }

    def load_plan(self) -> bool:
        """åŠ è½½æ‰§è¡Œè®¡åˆ’"""
        try:
            print(f"ğŸ“„ åŠ è½½æ‰§è¡Œè®¡åˆ’: {self.plan_path}")

            if not self.plan_path.exists():
                print(f"âŒ é”™è¯¯: æ‰§è¡Œè®¡åˆ’æ–‡ä»¶ä¸å­˜åœ¨ - {self.plan_path}")
                return False

            with open(self.plan_path, 'r', encoding='utf-8') as f:
                self.plan = json.load(f)

            # éªŒè¯å¿…éœ€å­—æ®µ
            required_fields = ["plan_id", "agent_id", "batches", "output_config"]
            for field in required_fields:
                if field not in self.plan:
                    print(f"âŒ é”™è¯¯: æ‰§è¡Œè®¡åˆ’ç¼ºå°‘å¿…éœ€å­—æ®µ '{field}'")
                    return False

            # éªŒè¯agent_id
            if self.plan.get("agent_id") != "E5":
                print(f"âŒ é”™è¯¯: æ­¤æ‰§è¡Œå¼•æ“ä»…æ”¯æŒE5æ™ºèƒ½ä½“ï¼Œå½“å‰è®¡åˆ’ä¸º: {self.plan.get('agent_id')}")
                return False

            # ç»Ÿè®¡ä»»åŠ¡æ•°
            self.total_tasks = sum(
                len(batch.get("tasks", []))
                for batch in self.plan.get("batches", [])
            )

            print(f"âœ… æ‰§è¡Œè®¡åˆ’åŠ è½½æˆåŠŸ")
            print(f"   ğŸ“‹ è®¡åˆ’ID: {self.plan.get('plan_id')}")
            print(f"   ğŸ¯ é¡¹ç›®åç§°: {self.plan.get('project_name')}")
            print(f"   ğŸ“¦ æ‰¹æ¬¡æ•°é‡: {len(self.plan.get('batches', []))}")
            print(f"   ğŸ¨ ä»»åŠ¡æ€»æ•°: {self.total_tasks}")

            return True

        except json.JSONDecodeError as e:
            print(f"âŒ é”™è¯¯: JSONæ ¼å¼é”™è¯¯ - {e}")
            return False
        except Exception as e:
            print(f"âŒ é”™è¯¯: åŠ è½½æ‰§è¡Œè®¡åˆ’å¤±è´¥ - {e}")
            return False

    def validate_input_files(self) -> bool:
        """éªŒè¯è¾“å…¥æ–‡ä»¶å®Œæ•´æ€§"""
        print("\nğŸ” éªŒè¯è¾“å…¥æ–‡ä»¶...")

        input_sources = self.plan.get("input_sources", {})

        # æ£€æŸ¥E4ä¸»å›¾ç›®å½•
        e4_dir = input_sources.get("e4_main_images_dir")
        if e4_dir:
            e4_path = Path(e4_dir)
            if not e4_path.exists():
                print(f"âš ï¸  è­¦å‘Š: E4ä¸»å›¾ç›®å½•ä¸å­˜åœ¨ - {e4_dir}")
                return False
            print(f"   âœ… E4ä¸»å›¾ç›®å½•: {e4_dir}")

        # æ£€æŸ¥å‚è€ƒå›¾åƒè·¯å¾„
        missing_files = []
        for batch in self.plan.get("batches", []):
            for task in batch.get("tasks", []):
                ref_image = task.get("reference_image_path")
                if ref_image and not Path(ref_image).exists():
                    missing_files.append(ref_image)

        if missing_files:
            print(f"âš ï¸  è­¦å‘Š: å‘ç° {len(missing_files)} ä¸ªç¼ºå¤±çš„å‚è€ƒå›¾åƒ")
            for f in missing_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"   - {f}")
            if len(missing_files) > 5:
                print(f"   ... è¿˜æœ‰ {len(missing_files) - 5} ä¸ª")
            return False

        print("   âœ… æ‰€æœ‰è¾“å…¥æ–‡ä»¶å®Œæ•´")
        return True

    def setup_output_directories(self):
        """åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„"""
        print("\nğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•...")

        output_config = self.plan.get("output_config", {})
        base_path = Path(output_config.get("base_path", "output/temp"))
        subdirs = output_config.get("subdirs", {
            "raw": "raw",
            "final": "final",
            "alternatives": "alternatives",
            "rejected": "rejected",
            "review": "review"
        })

        # åˆ›å»ºæ‰€æœ‰å­ç›®å½•
        for subdir_key, subdir_name in subdirs.items():
            subdir_path = base_path / subdir_name
            subdir_path.mkdir(parents=True, exist_ok=True)
            print(f"   âœ… {subdir_path}")

        # ä¿å­˜è¾“å‡ºè·¯å¾„
        self.output_base = base_path
        self.output_subdirs = {k: base_path / v for k, v in subdirs.items()}

    async def execute_single_task(self, task: Dict[str, Any], retry_config: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•ä¸ªä»»åŠ¡ï¼ˆå¸¦é‡è¯•ï¼‰

        Args:
            task: ä»»åŠ¡é…ç½®
            retry_config: é‡è¯•é…ç½®

        Returns:
            ä»»åŠ¡æ‰§è¡Œç»“æœ
        """
        task_id = task.get("task_id")
        shot_number = task.get("shot_number")
        reference_image = task.get("reference_image_path")
        variation_instruction = task.get("variation_instruction")

        retry_attempts = retry_config.get("retry_attempts", 3)
        retry_delays = retry_config.get("retry_delay_seconds", [2, 4, 8])

        print(f"   ğŸ¨ ä»»åŠ¡ {task_id} (é•œå¤´ {shot_number})...")

        for attempt in range(retry_attempts):
            try:
                # è°ƒç”¨APIç”Ÿæˆ
                result = self.api.generate_derivative_image(
                    reference_image_path=reference_image,
                    variation_instruction=variation_instruction,
                    output_path=self.output_subdirs["raw"] / f"shot_{shot_number}_derivative.png"
                )

                if result["success"]:
                    return {
                        "task_id": task_id,
                        "shot_number": shot_number,
                        "success": True,
                        "image_paths": result.get("image_paths", []),
                        "processing_time": result.get("processing_time", 0),
                        "attempts": attempt + 1
                    }
                else:
                    error_msg = result.get("error", "æœªçŸ¥é”™è¯¯")
                    print(f"      âš ï¸  å°è¯• {attempt + 1}/{retry_attempts} å¤±è´¥: {error_msg}")

                    # å¦‚æœè¿˜æœ‰é‡è¯•æœºä¼šï¼Œç­‰å¾…åé‡è¯•
                    if attempt < retry_attempts - 1:
                        delay = retry_delays[min(attempt, len(retry_delays) - 1)]
                        print(f"      â±ï¸  ç­‰å¾… {delay}ç§’åé‡è¯•...")
                        await asyncio.sleep(delay)
                    else:
                        # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                        return {
                            "task_id": task_id,
                            "shot_number": shot_number,
                            "success": False,
                            "error": error_msg,
                            "attempts": retry_attempts
                        }

            except Exception as e:
                print(f"      âŒ å°è¯• {attempt + 1}/{retry_attempts} å¼‚å¸¸: {str(e)}")

                if attempt < retry_attempts - 1:
                    delay = retry_delays[min(attempt, len(retry_delays) - 1)]
                    await asyncio.sleep(delay)
                else:
                    return {
                        "task_id": task_id,
                        "shot_number": shot_number,
                        "success": False,
                        "error": str(e),
                        "attempts": retry_attempts
                    }

    async def execute_batch(self, batch: Dict[str, Any], batch_index: int) -> List[Dict[str, Any]]:
        """
        æ‰§è¡Œæ‰¹æ¬¡ä»»åŠ¡ï¼ˆå¹¶å‘å¤„ç†ï¼‰

        Args:
            batch: æ‰¹æ¬¡é…ç½®
            batch_index: æ‰¹æ¬¡ç´¢å¼•

        Returns:
            æ‰¹æ¬¡æ‰§è¡Œç»“æœåˆ—è¡¨
        """
        batch_id = batch.get("batch_id")
        tasks = batch.get("tasks", [])
        reference_shot_id = batch.get("reference_shot_id")

        print(f"\nğŸ“¦ æ‰¹æ¬¡ {batch_index + 1} (ID: {batch_id}, å‚è€ƒä¸»å›¾: {reference_shot_id})")
        print(f"   ğŸ“Š ä»»åŠ¡æ•°é‡: {len(tasks)}")

        # è·å–å¹¶å‘é…ç½®
        execution_config = self.plan.get("execution_config", {})
        max_concurrent = execution_config.get("max_concurrent_requests", 5)

        # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
        task_coroutines = [
            self.execute_single_task(task, execution_config)
            for task in tasks
        ]

        # å¹¶å‘æ‰§è¡Œï¼ˆé™åˆ¶å¹¶å‘æ•°ï¼‰
        results = []
        for i in range(0, len(task_coroutines), max_concurrent):
            batch_coroutines = task_coroutines[i:i + max_concurrent]
            batch_results = await asyncio.gather(*batch_coroutines)
            results.extend(batch_results)

            # Checkpointæ£€æŸ¥
            checkpoint_interval = execution_config.get("checkpoint_interval", 10)
            if (i + len(batch_coroutines)) % checkpoint_interval == 0:
                self.save_checkpoint()

        return results

    def save_checkpoint(self):
        """ä¿å­˜æ‰§è¡Œè¿›åº¦æ£€æŸ¥ç‚¹"""
        checkpoint_path = self.output_base / "execution_checkpoint.json"

        self.checkpoint_data["last_update"] = datetime.now().isoformat()
        self.checkpoint_data["completed_count"] = self.completed_tasks
        self.checkpoint_data["failed_count"] = self.failed_tasks

        with open(checkpoint_path, 'w', encoding='utf-8') as f:
            json.dump(self.checkpoint_data, f, ensure_ascii=False, indent=2)

        print(f"      ğŸ’¾ Checkpointå·²ä¿å­˜: {checkpoint_path}")

    def generate_metadata(self):
        """ç”Ÿæˆæ‰§è¡Œå…ƒæ•°æ®å’Œäº¤ä»˜æ¸…å•"""
        print("\nğŸ“‹ ç”Ÿæˆæ‰§è¡Œå…ƒæ•°æ®...")

        output_config = self.plan.get("output_config", {})
        metadata_files = output_config.get("metadata_files", {})

        # 1. æ‰§è¡Œæ—¥å¿—
        execution_log_path = self.output_base / metadata_files.get("execution_log", "execution_log.json")
        execution_log_data = {
            "plan_id": self.plan.get("plan_id"),
            "execution_time": datetime.now().isoformat(),
            "total_tasks": self.total_tasks,
            "completed_tasks": self.completed_tasks,
            "failed_tasks": self.failed_tasks,
            "success_rate": f"{(self.completed_tasks / self.total_tasks * 100):.2f}%" if self.total_tasks > 0 else "0%",
            "tasks": self.execution_log
        }

        with open(execution_log_path, 'w', encoding='utf-8') as f:
            json.dump(execution_log_data, f, ensure_ascii=False, indent=2)
        print(f"   âœ… æ‰§è¡Œæ—¥å¿—: {execution_log_path}")

        # 2. E6äº¤ä»˜æ¸…å•
        e6_delivery_path = self.output_base / metadata_files.get("e6_delivery", "e6-delivery-manifest.yaml")
        e6_delivery_data = {
            "plan_id": self.plan.get("plan_id"),
            "project_name": self.plan.get("project_name"),
            "delivery_time": datetime.now().isoformat(),
            "phase": "E5-è¡ç”Ÿå›¾ç”Ÿæˆå®Œæˆ",
            "next_phase": "E6-è§†é¢‘æç¤ºè¯ç”Ÿæˆ",
            "statistics": {
                "total_shots": self.total_tasks,
                "generated_images": self.completed_tasks,
                "failed_images": self.failed_tasks
            },
            "output_directories": {
                "raw": str(self.output_subdirs["raw"]),
                "final": str(self.output_subdirs["final"]),
                "review": str(self.output_subdirs["review"])
            }
        }

        with open(e6_delivery_path, 'w', encoding='utf-8') as f:
            yaml.dump(e6_delivery_data, f, allow_unicode=True, sort_keys=False)
        print(f"   âœ… E6äº¤ä»˜æ¸…å•: {e6_delivery_path}")

    async def execute_plan(self):
        """æ‰§è¡Œå®Œæ•´è®¡åˆ’"""
        print("\n" + "=" * 80)
        print("ğŸš€ å¼€å§‹æ‰§è¡ŒE5è¡ç”Ÿå›¾ç”Ÿæˆè®¡åˆ’")
        print("=" * 80)

        start_time = datetime.now()

        # æ‰§è¡Œæ‰€æœ‰æ‰¹æ¬¡
        all_results = []
        for batch_index, batch in enumerate(self.plan.get("batches", [])):
            batch_results = await self.execute_batch(batch, batch_index)
            all_results.extend(batch_results)

            # ç»Ÿè®¡ç»“æœ
            for result in batch_results:
                if result["success"]:
                    self.completed_tasks += 1
                    self.checkpoint_data["completed_task_ids"].append(result["task_id"])
                else:
                    self.failed_tasks += 1
                    self.checkpoint_data["failed_task_ids"].append(result["task_id"])

                self.execution_log.append(result)

        # ç”Ÿæˆå…ƒæ•°æ®
        self.generate_metadata()

        end_time = datetime.now()
        total_time = (end_time - start_time).total_seconds()

        # æ‰“å°æ‰§è¡ŒæŠ¥å‘Š
        print("\n" + "=" * 80)
        print("ğŸ“Š E5æ‰§è¡ŒæŠ¥å‘Š")
        print("=" * 80)
        print(f"âœ… æ€»ä»»åŠ¡æ•°: {self.total_tasks}")
        print(f"âœ… æˆåŠŸç”Ÿæˆ: {self.completed_tasks}")
        print(f"âŒ å¤±è´¥ä»»åŠ¡: {self.failed_tasks}")
        print(f"ğŸ“ˆ æˆåŠŸç‡: {(self.completed_tasks / self.total_tasks * 100):.2f}%" if self.total_tasks > 0 else "0%")
        print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_base}")
        print("=" * 80)


def main():
    parser = argparse.ArgumentParser(description='æ‰§è¡ŒE5è¡ç”Ÿå›¾ç”Ÿæˆè®¡åˆ’')
    parser.add_argument('--plan', required=True, help='æ‰§è¡Œè®¡åˆ’JSONæ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    # åˆ›å»ºæ‰§è¡Œå¼•æ“
    engine = E5ExecutionEngine(args.plan)

    # åŠ è½½è®¡åˆ’
    if not engine.load_plan():
        sys.exit(1)

    # éªŒè¯è¾“å…¥
    if not engine.validate_input_files():
        print("\nâš ï¸  è­¦å‘Š: è¾“å…¥æ–‡ä»¶éªŒè¯å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ...")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    engine.setup_output_directories()

    # æ‰§è¡Œè®¡åˆ’
    try:
        asyncio.run(engine.execute_plan())
        print("\nğŸ‰ E5æ‰§è¡Œè®¡åˆ’å®Œæˆï¼")
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        engine.save_checkpoint()
        sys.exit(130)
    except Exception as e:
        print(f"\n\nâŒ æ‰§è¡Œå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        engine.save_checkpoint()
        sys.exit(1)


if __name__ == "__main__":
    main()
